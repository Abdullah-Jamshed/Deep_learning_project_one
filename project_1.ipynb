{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nk8u6l34PJad"
   },
   "source": [
    "# Step 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "46XWXIMnRUuO"
   },
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "EPoihJws4uFP",
    "outputId": "47f69a53-8db5-41e7-9f6c-507af1687b9d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xzGVWT7vR-Zf"
   },
   "source": [
    "### Initializing the random number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UqmoVqUB4kqP"
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SQoB8Z1ARfuW"
   },
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VG0YJRa1hZkr"
   },
   "outputs": [],
   "source": [
    "dataframe = pandas.read_csv(\"C:/Users/FC/Documents/Deep_Learning_Project_One/sonar.csv\", header=None)\n",
    "dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:60].astype(float)\n",
    "Y = dataset[:,60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D4Gdo1z3RjFp"
   },
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U6ON4TuF9DKE"
   },
   "outputs": [],
   "source": [
    "encoded_Y = LabelEncoder().fit_transform(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kElVAy9WOyul"
   },
   "source": [
    "## Step 2. Baseline Neural Network Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "73bIcDtX5YWg",
    "outputId": "9c8b56e9-cbf5-4047-d6f6-ebf4f0d3ba38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\FC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\FC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Results: 84.16% (5.35%)\n"
     ]
    }
   ],
   "source": [
    "def create_baseline():\n",
    "    # create model, write code below\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, activation='relu', input_shape=(60,)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model, write code below\n",
    "    model.compile(optimizer='Adam',loss= 'binary_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5,verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, encoded_Y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zuFfn2ssOGFB"
   },
   "source": [
    "## **Step 3. Re-Run The Baseline Model With Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "jv345O_yAxpB",
    "outputId": "3fdee2e7-c05d-44a1-be96-4787bd14bcb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 84.59% (6.01%)\n"
     ]
    }
   ],
   "source": [
    "def create_baseline():\n",
    "    # create model, write code below\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, activation='relu', input_shape=(60,)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model, write code below\n",
    "    model.compile(optimizer='Adam',loss= 'binary_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# evaluate baseline model with standardized dataset\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IaBr4c_rQD_b"
   },
   "source": [
    "## Step 4. Tuning Layers and Number of Neurons in The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MyVMcyuKQhaC"
   },
   "source": [
    "### Evaluating a Smaller Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "LVPfP_Rs9zMu",
    "outputId": "bf7fdbe1-425d-4bac-dddc-3ff1071de60d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smaller: 82.75% (6.33%)\n"
     ]
    }
   ],
   "source": [
    "# smaller model\n",
    "def create_smaller():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, activation='relu', input_shape=(60,)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(optimizer='Adam',loss= 'binary_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_smaller, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IAey3FHvQyjA"
   },
   "source": [
    "### Evaluating a Larger Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HGQwKfhS_3Bl"
   },
   "outputs": [],
   "source": [
    "# larger model\n",
    "def create_larger():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, activation='relu', input_shape=(60,)))\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(optimizer='Adam',loss= 'binary_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_larger, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w9C9f9wTxjrr"
   },
   "source": [
    "## Step 5: Really Scaling up: developing a model that overfits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IwrE6J8DpwZQ"
   },
   "outputs": [],
   "source": [
    "# overfit model\n",
    "def create_larger():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(600, activation='relu', input_shape=(60,)))\n",
    "    model.add(Dense(300, activation='relu'))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(optimizer='Adam',loss= 'binary_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_larger, epochs=150, batch_size=5,verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wlBMCeSS-Y-b"
   },
   "source": [
    "## Step 6: Tuning the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "5EiPk-jwYqYk",
    "outputId": "420d0b55-6c71-4ead-9677-caaacf274e79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 82.66% (4.47%)\n"
     ]
    }
   ],
   "source": [
    "# tuned model\n",
    "def tuned_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, activation='relu', input_shape=(60,)))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model, write code below\n",
    "    model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# evaluate baseline model with standardized dataset\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=tuned_model, epochs=50, batch_size=5,verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KQgD5fvs9UGj"
   },
   "source": [
    "## Step 7: Rewriting the code using the Keras (Functional API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "DG5YzHE2nnmM",
    "outputId": "e1f411d4-52f8-4468-c839-b40350ff3c1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 84.59% (6.01%)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "def funtional_model():\n",
    "    # create model, write code below\n",
    "    inputs = keras.Input(shape=(60,))\n",
    "    x = layers.Dense(60,activation='relu')(inputs)\n",
    "    outputs = layers.Dense(1,activation='sigmoid')(x)\n",
    "    model = keras.Model(inputs,outputs)\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=funtional_model, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Functional Api: Accuracy %.2f%%, Error (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2AChfLIGTcj6"
   },
   "source": [
    "## Step 7: Rewriting the code using the Keras (Model Subclassing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lV6h2N0NSyUn"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "class Mymodel(keras.Model):\n",
    "    def__init__(self):\n",
    "        super(Mymodel).__init__()\n",
    "        self.dense1 = Dense(60, activation = 'relu')\n",
    "        self.dense2 = Dense(1, activation = 'sigmoid')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        return self.dense2(x)\n",
    "\n",
    "    \n",
    "\n",
    "def subclass_model():\n",
    "    inputs = keras.Input(shape=(60,))\n",
    "    model = MyModel()\n",
    "    outputs = model.call(inputs)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile model, write code below\n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "  numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=subclass_model, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Model Subclassing: Accuracy %.2f%%, Error (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "awDk92sfaTqM"
   },
   "source": [
    "## Step 9: Rewriting the code without using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uvQ8ihpwaSWV"
   },
   "outputs": [],
   "source": [
    "data = pandas.read_csv(\"C:/Users/FC/Documents/Deep_Learning_Project_One/sonar.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2tyB9WeCbb-y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\FC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data[60][data[60]=='M']=1\n",
    "data[60][data[60]=='R']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xrv96z2wbdxG"
   },
   "outputs": [],
   "source": [
    "data_values = data.values\n",
    "numpy.random.seed(7)\n",
    "numpy.random.shuffle(data_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jevraqCibjpy"
   },
   "outputs": [],
   "source": [
    "train_data = data_values[:167,0:60].astype(float)\n",
    "train_labels =data_values[:167,60]\n",
    "test_data= data_values[167:,0:60].astype(float)\n",
    "test_labels= data_values[167:,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1bCkblfqboAc"
   },
   "outputs": [],
   "source": [
    "def keras_model():\n",
    "    # create model, write code below\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(60, activation='relu', input_shape=(60,)))\n",
    "    model.add(layers.Dense(1,activation='sigmoid'))\n",
    "    # Compile model, write code below\n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CwdmJ1iSb6hS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "k = 4\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_labels[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    partial_train_data = np.concatenate([train_data[:i * num_val_samples],train_data[(i + 1) * num_val_samples:]],axis=0)\n",
    "    partial_train_targets = np.concatenate([train_labels[:i * num_val_samples],train_labels[(i + 1) * num_val_samples:]],axis=0)\n",
    "    model = keras_model()\n",
    "    model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=0)\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "118Jjf0EcGff"
   },
   "outputs": [],
   "source": [
    "result = model.model.evaluate(test_data,test_labels)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "project 1",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
